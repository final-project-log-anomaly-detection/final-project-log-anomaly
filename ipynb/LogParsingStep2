{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOv0vRsG860Kt2txseDJiBW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"id":"CiAHPV-4wD87","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681207081502,"user_tz":-420,"elapsed":52381,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}},"outputId":"74ea7289-b7e4-4df7-896e-69c051aa8541"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# input\n","csv_dir = \"/content/drive/MyDrive/Colab Notebooks/Drain_result/\"\n","dataset_prefix = \"BGL.\"\n","csv_structured = csv_dir + dataset_prefix + \"log_ident_structured.csv\"\n","csv_template = csv_dir + dataset_prefix + \"log_ident_templates.csv\"\n","\n","# test_portion = 0.6\n","cv = 3"],"metadata":{"id":"lZlYTFFPwIwQ","executionInfo":{"status":"ok","timestamp":1681206962898,"user_tz":-420,"elapsed":7,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# output\n","output_dir = \"/content/drive/MyDrive/Colab Notebooks/Parsed_Log/\"\n","output_prefix = \"2ndstep-log-parsing.\"\n","\n","pkl_train_path = list()\n","pkl_test_path = list()\n","pkl_prefix = output_dir + dataset_prefix + output_prefix\n","\n","for i in range(cv):\n","  # trainset\n","  pkl_train_path.append({\n","      \"structured\"    : f\"{pkl_prefix}cv{i}_train.log_ident_structured.pkl\",\n","      \"template\"      : f\"{pkl_prefix}cv{i}_train.log_ident_templates.pkl\",\n","      \"2nd.template\"  : f\"{pkl_prefix}cv{i}_train.2nd_log_ident_templates.pkl\"\n","  })\n","  # testset\n","  pkl_test_path.append({\n","      \"structured\"    : f\"{pkl_prefix}cv{i}_test.log_ident_structured.pkl\",\n","      \"template\"      : f\"{pkl_prefix}cv{i}_test.log_ident_templates.pkl\",\n","      \"2nd.template\"  : f\"{pkl_prefix}cv{i}_test.2nd_log_ident_templates.pkl\"\n","  })\n","  \n","# # trainset\n","# pkl_train_structured_path = output_dir + dataset_prefix + output_prefix + \"train.log_ident_structured.pkl\"\n","# pkl_train_template_path = output_dir + dataset_prefix + output_prefix + \"train.log_ident_templates.pkl\"\n","# pkl_train_2ndtemplate_path = output_dir + dataset_prefix + output_prefix + \"train.2nd_log_ident_templates.pkl\"\n","# # testset\n","# pkl_test_structured_path = output_dir + dataset_prefix + output_prefix + \"test.log_ident_structured.pkl\"\n","# pkl_test_template_path = output_dir + dataset_prefix + output_prefix + \"test.log_ident_templates.pkl\"\n","# pkl_test_2ndtemplate_path = output_dir + dataset_prefix + output_prefix + \"test.2nd_log_ident_templates.pkl\""],"metadata":{"id":"4_ZiCC2ML-qt","executionInfo":{"status":"ok","timestamp":1681206962900,"user_tz":-420,"elapsed":7,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from nltk.tokenize import RegexpTokenizer\n","\n","import os\n","from tqdm import tqdm\n","tqdm.pandas()\n","\n","import re\n","# from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","\n","seed = 42\n","np.random.seed(seed)"],"metadata":{"id":"gnQeIM0Rwmag","executionInfo":{"status":"ok","timestamp":1681206965188,"user_tz":-420,"elapsed":2295,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from scipy.stats import entropy\n","\n","class EntropyBasedLogParsingStep2():\n","  def __init__(self, regex_tokenise, threshold=1., \n","               content_col_name=\"Content\",\n","               eventid_col_name=\"EventId\",\n","               token_col_name=\"Tokens\", \n","               len_col_name=\"length\"):\n","    self.tokenizer = RegexpTokenizer(regex_tokenise)\n","\n","    self.content_col_name = content_col_name\n","    self.eventid_col_name = eventid_col_name\n","    self.token_col_name = token_col_name\n","    self.len_col_name = len_col_name\n","    self.eventId_len_col_name = f\"{eventid_col_name}_{self.len_col_name}\"\n","\n","    self.threshold = threshold\n","\n","  def set_threshold(self, new_threshold):\n","    self.threshold = new_threshold\n","\n","  def __prepare_X(self, X):\n","    uX = pd.DataFrame(\n","        X[[self.content_col_name, self.eventid_col_name]]\n","          .groupby(self.content_col_name)\n","          .first()\n","          .reset_index()\n","        )\n","    print(\"tokenize unique contents\")\n","    uX[self.token_col_name] = uX[self.content_col_name].progress_apply(self.tokenizer.tokenize)\n","\n","    print(\"measure token sequence length\")\n","    uX[self.len_col_name] = uX[self.token_col_name].progress_apply(len)\n","\n","    print(f\"build new column: '{self.eventId_len_col_name}'\")\n","    uX[self.eventId_len_col_name] = uX[[self.eventid_col_name, self.len_col_name]].progress_apply(\n","        lambda x: f\"{x[0]}_{x[1]}\", axis=1\n","    )\n","\n","    return uX\n","\n","  def __build_tokens_group(self, uX):\n","    count_Id = { k: v \\\n","                for k, v in uX.groupby(self.eventId_len_col_name)\n","                  .count()\n","                  .sort_index()[self.token_col_name]\n","                  .items() }\n","    \n","    sort_uX = uX.sort_values(self.eventId_len_col_name).reset_index(drop=True)\n","    tokens = sort_uX[self.token_col_name].to_numpy()\n","\n","    start = 0\n","    tokens_groupby_id = dict()\n","    print(\"group tokens by id\")\n","    for id, n in tqdm(count_Id.items()):\n","      end = start + n\n","      tokens_groupby_id[id] = np.array([ seq for seq in tokens[start:end] ], dtype=\"str\")\n","      start = end\n","\n","    return tokens_groupby_id\n","\n","  def __has_fit(self): return hasattr(self, \"entropy_id\") and hasattr(self, \"unique_log_message\")\n","\n","  def fit(self, X, re_fit=False):\n","    if (not self.__has_fit()) or re_fit: self.__first_fit(X)\n","    else: self.__continue_fit(X)\n","\n","  def transform(self, X, threshold=None):\n","    if threshold is not None: self.threshold = threshold\n","    uX = self.__prepare_X(X)\n","    tokens_groupby_id = self.__build_tokens_group(uX)\n","    know_id = self.tokens_groupby_id.keys()\n","    focus_id = uX.query(f\"{self.eventId_len_col_name} not in @know_id\")[self.eventId_len_col_name].values\n","\n","    print(\"calculate unknow pattern entropy\")\n","    unkonwn_entropy_id = {\n","        id : [ entropy(np.unique(t, return_counts=True)[1]) \\\n","                  for t in tokens_groupby_id[id].T ] \\\n","                    for id in tqdm(focus_id, total=len(focus_id))\n","    }\n","      \n","    Y = list()\n","    Y_tokens = list()\n","    Y_params = list()\n","    print(\"transform X to Y\")\n","    for x in tqdm(X[[self.eventid_col_name, self.content_col_name]].values):\n","      token_seq = self.tokenizer.tokenize(x[1])\n","      id = f\"{x[0]}_{len(token_seq)}\"\n","      _entropy = self.entropy_id[id] if id in self.entropy_id.keys() else unkonwn_entropy_id[id]\n","      _entp_lt_th = np.array(_entropy) < self.threshold\n","      \n","      y_tokens = [ token if _entp_lt_th[i] else \"<*>\" for i, token in enumerate((token_seq)) ]\n","      y_params = [ token for i, token in enumerate((token_seq)) if not _entp_lt_th[i] ]\n","      y = \" \".join(y_tokens)\n","      \n","      Y.append(y)\n","      Y_tokens.append(y_tokens)\n","      Y_params.append(y_params)\n","\n","    return Y, Y_tokens, Y_params\n","\n","  def __first_fit(self, X):\n","    uX = self.__prepare_X(X)\n","    self.tokens_groupby_id = self.__build_tokens_group(uX)\n","\n","    self.unique_log_message = uX.sort_values(self.eventId_len_col_name).reset_index(drop=True)\n","    print(\"calculate entropy\")\n","    self.entropy_id = {\n","      id : [ entropy(np.unique(t, return_counts=True)[1]) \\\n","        for t in self.tokens_groupby_id[id].T ] \\\n","          for id in tqdm(self.tokens_groupby_id.keys())\n","    }\n","\n","  def __continue_fit(self, X):\n","    assert self.__has_fit(), \\\n","                \"require to call __first_fit before\"\n","    X = X[[self.content_col_name, self.eventid_col_name]].copy()\n","    oldX = self.unique_log_message[\n","        [self.content_col_name, self.eventid_col_name]\n","        ].copy()\n","\n","    updateX = pd.concat([oldX, X], ignore_index=True)\n","\n","    self.__first_fit(X=updateX)\n","\n","  def map_template_with_known_id(self, X, know_template_df, template_col_name):\n","    eventId = X[self.eventid_col_name].values.astype('str')\n","    know_template = { x[1]: x[0] \\\n","                     for x in know_template_df[[self.eventid_col_name ,template_col_name]].items() }\n","    mapped_id = [ eventId[i] if tem not in know_template.keys() else know_template[tem] \\\n","                for i, tem in tqdm( enumerate(X[template_col_name]) ) ]\n","    return mapped_id\n","\n"],"metadata":{"id":"ky3c2_gGBW_L","executionInfo":{"status":"ok","timestamp":1681208209343,"user_tz":-420,"elapsed":6,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["class EntityLabalingEncoder():\n","\n","  DEFAULT_ENTITY = [\n","    (\"ipV4\", [r\"([0-9]{1,3}\\.){3}[0-9]{1,3}\"]),\n","    (\"ipV6\", [r\"([0-9A-F]{4}\\:){4}(\\:)?\", r\"([0-9a-f]{4}\\:){4}(\\:)?\", r\"([0-9A-F]{4}\\:){7}[0-9A-F]{4}\", r\"([0-9a-f]{4}\\:){7}[0-9A-F]{4}\"]),\n","    (\"mac\", [r\"([0-9A-F]{2}\\:){5}[0-9A-F]{2}\", r\"([0-9a-f]{2}\\:){5}[0-9a-f]{2}\", r\"([0-9A-F]{2}\\-){5}[0-9A-F]{2}\", r\"([0-9a-f]{2}\\-){5}[0-9a-f]{2}\"]),\n","    (\"time\", [r\"([0-9]{2}:){2}[0-9]{2}\"]),\n","    (\"path\", [r\"([\\w\\d$&+,:;=?@#|'<>.^*()%!-]+)?(\\/[\\w\\d$&+,:;=?@#|'<>.^*()%!-]+)+\", r\"([\\w\\d$&+,:;=?@#|'<>.^*()%!-]+)?(\\\\[\\w\\d$&+,:;=?@#|'<>.^*()%!-]+)+\"]),\n","    (\"integer\", [r\"(\\-?)[0-9]+\"]),\n","    (\"floar\", [r\"(\\-?)[0-9]+.[0-9]+\"]),\n","    (\"identifier\", [r\"\\w*[_]*\\w*\"]),\n","  ]\n","\n","  DEFAULT_PRIORITY = { entity[0]: i for i, entity in enumerate(DEFAULT_ENTITY) }\n","\n","  def __init__(self, \n","               entity_regex,\n","              #  regex_tokenise,\n","              #  content_col_name, \n","               template_col_name,\n","               params_col_name,\n","               tid_col_name = \"TID\",\n","               residual_entity = \"identifier\",\n","               use_default = True,\n","               ):\n","    # self.tokenizer = RegexpTokenizer(regex_tokenise)\n","    self.entity_regex = entity_regex\n","    self.entity_priority = { entity[0]: i for i, entity in enumerate(entity_regex) }\n","\n","    # self.content_col_name = content_col_name\n","    self.template_col_name = template_col_name\n","    self.params_col_name = params_col_name\n","    self.tid_col_name = tid_col_name\n","\n","    self.residual_entity = residual_entity\n","    self.use_default = use_default\n","\n","  def __prepare_X(self, X):\n","    X = X[[\n","        # self.content_col_name, \n","        self.template_col_name, \n","        self.params_col_name\n","        ]].copy()\n","    \n","    unique_template = X[self.template_col_name].unique()\n","    number_template = len(unique_template)\n","    id_len = int(np.ceil(np.log10(number_template)) + 1)\n","    id_prefix = '0' * id_len\n","\n","    id_map = { temp: 'E' + f\"{id_prefix}{i}\"[-id_len:] for i, temp in tqdm(enumerate(unique_template)) }\n","    X[self.tid_col_name] = X[self.template_col_name].map(lambda t: id_map[t])\n","\n","    return X\n","\n","  def __group_params_by_id(self, X):\n","    count_id = { id: n for id, n in X.groupby(self.tid_col_name)\\\n","                  .count()\\\n","                  .sort_index()[self.params_col_name]\\\n","                  .items() }\n","\n","    params = X.sort_values(self.tid_col_name)[self.params_col_name].values\n","\n","    params_group = dict()\n","    start = 0\n","    for id, n in tqdm(count_id.items()):\n","      end = start + n\n","      params_group[id] = np.array(params[start:end])\n","      start = end\n","\n","    return params_group\n","\n","  def __labeling(self, params):\n","    if len(params) < 1: return params\n","\n","    Y = list()\n","    for p in params:\n","      is_match = False\n","      for entity in self.entity_regex:\n","        for regex in entity[1]:\n","          is_match = re.fullmatch(regex, p) is not None\n","          if is_match:\n","            Y.append(entity[0])\n","            break\n","        if is_match: break\n","      if is_match: continue\n","      elif not self.use_default:\n","        Y.append(self.residual_entity)\n","        continue\n","\n","      for entity in self.DEFAULT_ENTITY:\n","        for regex in entity[1]:\n","          is_match = re.fullmatch(regex, p) is not None\n","          if is_match:\n","            Y.append(entity[0])\n","            break\n","        if is_match: break\n","      if not is_match: Y.append(self.residual_entity)\n","\n","    return Y\n","\n","  def __labeling_transpose(self, params):\n","    if len(params) < 1: return\n","\n","    Y = list()\n","    for p in params:\n","      is_match = False\n","      for entity in self.entity_regex:\n","        for regex in entity[1]:\n","          is_match = re.fullmatch(regex, p) is not None\n","          if is_match:\n","            Y.append(entity[0])\n","            break\n","        if is_match: break\n","      if is_match: continue\n","      elif not self.use_default:\n","        Y.append(self.residual_entity)\n","        continue\n","\n","      for entity in self.DEFAULT_ENTITY:\n","        for regex in entity[1]:\n","          is_match = re.fullmatch(regex, p) is not None\n","          if is_match:\n","            Y.append(entity[0])\n","            break\n","        if is_match: break\n","      if not is_match: Y.append(self.residual_entity)\n","\n","    if Y.count(Y[0]) == len(Y): return Y[0]\n","    Y_priority = [\n","        -1 if y == self.residual_entity else \\\n","        self.DEFAULT_PRIORITY[y] if y in self.DEFAULT_PRIORITY and self.use_default else \\\n","        self.entity_priority[y] + len(self.DEFAULT_ENTITY) for y in Y\n","    ]\n","    \n","    argmax = np.argmax(Y_priority)\n","    label = Y[argmax]\n","\n","    return label\n","\n","  def transform(self, X):\n","    # X = self.__prepare_X(X)\n","    # params_groupby_id = self.__group_params_by_id(X)\n","    # print(np.array([ [v for v in l] for l in params_groupby_id[\"E01010\"] ], dtype=\"str\") )\n","    # params_labeled = { id: [ self.__labeling_transpose(params) for params in np.array([ [ v for v in l ] for l in P ], dtype=\"str\").T ] \\\n","    #                   for id, P in tqdm(params_groupby_id.items()) }\n","    \n","    # Y = X[self.tid_col_name].map(lambda id: params_labeled[id])\n","    Y = X[self.params_col_name].progress_apply(self.__labeling)\n","    return Y\n","\n","  def __merge_template_params(self, template, params, labels):\n","    y = template\n","    for p, l in zip(params, labels):\n","      if re.fullmatch(\"[^A-Za-z0-9]{1}\", p): tag = p\n","      else: tag = f\"<{l}>\"\n","\n","      y = y.replace(\"<*>\", tag, 1)\n","\n","    return y\n","\n","  def __pop_non_params(self, params):\n","    return [ p for p in params if not re.fullmatch(\"[^A-Za-z0-9]{1}\", p) ]\n","\n","  def merge_template_params(self, X, labeled_col_name):\n","    Y = X[[self.template_col_name, self.params_col_name, labeled_col_name]]\\\n","        .progress_apply(\n","          lambda row: self.__merge_template_params(*row)\n","        , axis=1)\n","    P = X[self.params_col_name].progress_apply(self.__pop_non_params)\n","    return Y, P"],"metadata":{"id":"XtM491U3Ixut","executionInfo":{"status":"ok","timestamp":1681208210502,"user_tz":-420,"elapsed":2,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["def define_dtype(df, dtype_map, copy=False):\n","  if copy: df = df.copy()\n","  \n","  for col, dtype in dtype_map.items():\n","    if col not in df.columns: continue\n","    if dtype.startswith(\"datetime_format_\"):\n","      dtype, format = dtype.split(\"_format_\")\n","      df[col] = pd.to_datetime(df[col], format=format)\n","    elif dtype == \"_drop_\": df = df.drop(columns=[col])\n","    else: df[col] = df[col].astype(dtype)\n","  \n","  return df"],"metadata":{"id":"CU0WDpHEwoll","executionInfo":{"status":"ok","timestamp":1681206965191,"user_tz":-420,"elapsed":9,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def build_template_df(X):\n","  templates = [ tem for tem in X.value_counts().index]\n","  frequecy = [ freq for freq in X.value_counts().values]\n","  id_len = int(np.ceil(np.log10(len(templates))) + 1)\n","  id = [ \"TID\" + f\"{'0' * id_len}{i}\"[-id_len:] for i in range(len(templates)) ]\n","\n","  return pd.DataFrame({\n","      \"EventId\": id,\n","      \"Template\": templates,\n","      \"Frequency\": frequecy,\n","  })"],"metadata":{"id":"TkUOn8nRQb_3","executionInfo":{"status":"ok","timestamp":1681206965192,"user_tz":-420,"elapsed":9,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["thunderbird_entity = [\n","    (\"day\", [r\"Mon\", r\"Tue\", r\"Wed\", r\"Thu\", r\"Fri\", r\"Sat\", r\"Sun\"]),\n","    (\"month\", [r\"Jan\", r\"Feb\", r\"Mar\", r\"Apr\", r\"May\", r\"Jun\", r\"Jul\", r\"Aug\", r\"Sep\", r\"Oct\", r\"Nov\", r\"Dec\"]),\n","    (\"status\", [r\"enabled\", r\"disabled\", r\"loaded\", r\"status\", \"registered\", \"reserved\", \"usable\", \"succeeded\"]),\n","    (\"function\", [r\"shutdown\", r\"startup\", r\"reboot\", r\"\\/([A-Za-z]*):\"]),\n","    (\"hexadecimal\", [r\"[0-9a-f]{11}\", r\"[0-9a-f]{13}\", r\"[0-9a-f]{16}\", r\"0x[0-9a-f]+\"]),\n","    (\"range\", [r\"[0-9a-f]{16}-[0-9a-f]{16}\", r\"([0-9]+)-([0-9]+)\"]),\n","    (\"fraction\", [\"[0-9]+k?/[0-9]+k?\"]),\n","    (\"quantity\", [ \"[0-9]+k\", \"[0-9]+[KMG]?bytes\"]),\n","    (\"ip\", [\n","        \"([0-9]{1,3}\\.){3}[0-9]{1,3}#[0-9]+\",\n","        \"([0-9]{1,3}\\.){3}[0-9]{1,3}:[0-9]+\",\n","        \"(([0-9a-f]{0,4})*:){3}([0-9]{1,3}\\.){3}[0-9]{1,3}\"\n","        ]\n","    ),\n","    (\"id\", [\n","        \"#[0-9]+#('s)?\",\n","        \"#[0-9]+#@#[0-9]+#\"\n","        \"R[0-9]{6}\", \n","        \"Thunderbird_[A-Z]{1}[0-9]{1}\",\n","        \"[0-9]{10}.[0-9]{3}:[0-9]{1}\"\n","        ]\n","    )\n","]"],"metadata":{"id":"FYEEaD09JZjV","executionInfo":{"status":"ok","timestamp":1681206965192,"user_tz":-420,"elapsed":9,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["struct_log = pd.read_csv(csv_structured)\n","template_log = pd.read_csv(csv_template)"],"metadata":{"id":"HDR5IDbzwqnc","executionInfo":{"status":"ok","timestamp":1681207156096,"user_tz":-420,"elapsed":29266,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["struct_dtype = {\n","    \"LineId\": \"int64\",\n","    \"Label\": \"category\",\n","    \"Timestamp\": \"int64\",\n","    \"Date\": \"datetime_format_%Y.%m.%d\",\n","    \"Node\": \"str\",\n","    \"Time\": \"datetime_format_%Y-%m-%d-%H.%M.%S.%f\",\n","    \"NodeRepeat\": \"string\",\n","    \"Type\": \"string\",\n","    \"Component\": \"string\",\n","    \"Level\": \"string\",\n","    \"Content\": \"string\",\n","    \"EventId\": \"string\",\n","    \"EventTemplate\": \"string\",\n","    \"EventTemplateIdent\": \"string\",\n","    \"ParameterList\": \"object\",\n","}\n","\n","template_dtype = {\n","    \"EventId\": \"string\",\n","    \"EventTemplateIdent\": \"string\",\n","    \"Occurrences\": \"int64\"\n","}"],"metadata":{"id":"HidcbqeYwsgl","executionInfo":{"status":"ok","timestamp":1681207159844,"user_tz":-420,"elapsed":3,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["struct_log = define_dtype(struct_log, struct_dtype)\n","template_log = define_dtype(template_log, template_dtype)"],"metadata":{"id":"d6YNtyAJwume","executionInfo":{"status":"ok","timestamp":1681207187533,"user_tz":-420,"elapsed":25102,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["struct_log.info()"],"metadata":{"id":"PT2FcZhNztNK","executionInfo":{"status":"ok","timestamp":1681207193682,"user_tz":-420,"elapsed":6,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}},"outputId":"34f1c886-1246-42c6-daac-919341ef0ed2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 4713493 entries, 0 to 4713492\n","Data columns (total 15 columns):\n"," #   Column              Dtype         \n","---  ------              -----         \n"," 0   LineId              int64         \n"," 1   Label               category      \n"," 2   Timestamp           int64         \n"," 3   Date                datetime64[ns]\n"," 4   Node                object        \n"," 5   Time                datetime64[ns]\n"," 6   NodeRepeat          string        \n"," 7   Type                string        \n"," 8   Component           string        \n"," 9   Level               string        \n"," 10  Content             string        \n"," 11  EventId             string        \n"," 12  EventTemplate       string        \n"," 13  EventTemplateIdent  string        \n"," 14  ParameterList       object        \n","dtypes: category(1), datetime64[ns](2), int64(2), object(2), string(8)\n","memory usage: 508.0+ MB\n"]}]},{"cell_type":"code","source":["def pipeline(trainset, train_save_path, testset, test_save_path, entity_dict):\n","    print(\"TRAIN SECTION\")\n","    train_eventId = trainset[\"EventId\"]\n","    train_template = template_log.query(\"EventId in @train_eventId\")\n","\n","    print(\"Log Parsing 2nd Step\")\n","    logparser = EntropyBasedLogParsingStep2(\"[^\\s[\\](),=<>{}+*]+\")\n","    logparser.fit(X=trainset, re_fit=True)\n","\n","    all_entropy = pd.Series([ entp \\\n","                          for entp_seq in logparser.entropy_id.values() \\\n","                          for entp in entp_seq ])\n","    th = all_entropy[all_entropy > 0.].quantile(0.01)\n","    print(f\"threshold: {th}\")\n","    result = logparser.transform(trainset, th)\n","    result = pd.DataFrame({\n","    \"Template\": result[0],\n","    \"TemplateTokenized\": result[1],\n","    \"Parameters\": result[2]\n","    })\n","    print(\"(Parameters) measure list length\")\n","    result[\"NumParams\"] = result[\"Parameters\"].progress_apply(len)\n","\n","    print(\"Entity Labeling\")\n","    labeler = EntityLabalingEncoder(\n","    entity_regex=entity_dict,\n","    template_col_name=\"Template\",\n","    params_col_name=\"Parameters\",\n","    )\n","\n","    result[\"LabeledParams\"] = labeler.transform(result)\n","    labeled_template, params = labeler.merge_template_params(result, \"LabeledParams\")\n","    result[\"LabeledTemplate\"] = labeled_template\n","    result[\"Parameters\"] = params\n","\n","    print(\"('ParameterList') parse string to list\")\n","    trainset[\"ParameterList\"] = trainset[\"ParameterList\"].progress_apply(\n","    lambda x: [ p.strip(\"'\") for p in x.strip(\"[\").strip(\"]\").split(\", \") if len(p) > 0 ]\n","    )\n","    print(\"('ParameterList') measure list length\")\n","    trainset[\"ParameterList_length\"] = trainset[\"ParameterList\"].progress_apply(len)\n","\n","    print(\"prepare saving\")\n","    trainset[\"LabeledTemplate\"] = result[\"LabeledTemplate\"]\n","    trainset[\"Parameters\"] = result[\"Parameters\"]\n","    trainset_template_2ndstep = build_template_df(trainset[\"LabeledTemplate\"])\n","\n","    print(\"saving:\")\n","    print(f\"- {train_save_path['structured']}\")\n","    trainset.to_pickle(train_save_path['structured'])\n","    print(f\"- {train_save_path['template']}\")\n","    train_template.to_pickle(train_save_path['template'])\n","    print(f\"- {train_save_path['2nd.template']}\")\n","    trainset_template_2ndstep.to_pickle(train_save_path['2nd.template'])\n","\n","    print(\"TEST SECTION\")\n","    test_eventId = testset[\"EventId\"]\n","    test_template = template_log.query(\"EventId in @test_eventId\")\n","\n","    print(\"Log Parsing 2nd Step\")\n","    test_result = logparser.transform(testset, th)\n","\n","    test_result = pd.DataFrame({\n","    \"Template\": test_result[0],\n","    \"TemplateTokenized\": test_result[1],\n","    \"Parameters\": test_result[2]\n","    })\n","    print(\"(Parameters) measure list length\")\n","    test_result[\"NumParams\"] = test_result[\"Parameters\"].progress_apply(len)\n","\n","    print(\"Entity Labeling\")\n","    test_result[\"LabeledParams\"] = labeler.transform(test_result)\n","    labeled_template, params = labeler.merge_template_params(test_result, \"LabeledParams\")\n","    test_result[\"LabeledTemplate\"] = labeled_template\n","    test_result[\"Parameters\"] = params\n","\n","    print(\"('ParameterList') parse string to list\")\n","    testset[\"ParameterList\"] = testset[\"ParameterList\"].progress_apply(\n","    lambda x: [ p.strip(\"'\") for p in x.strip(\"[\").strip(\"]\").split(\", \") if len(p) > 0 ]\n","    )\n","    print(\"('ParameterList') measure list length\")\n","    testset[\"ParameterList_length\"] = testset[\"ParameterList\"].progress_apply(len)\n","\n","    print(\"prepare saving\")\n","    testset[\"LabeledTemplate\"] = test_result[\"LabeledTemplate\"]\n","    testset[\"Parameters\"] = test_result[\"Parameters\"]\n","    testset_template_2ndstep = build_template_df(testset[\"LabeledTemplate\"])\n","\n","    print(\"saving:\")\n","    print(f\"- {test_save_path['structured']}\")\n","    testset.to_pickle(test_save_path['structured'])\n","    print(f\"- {test_save_path['template']}\")\n","    test_template.to_pickle(test_save_path['template'])\n","    print(f\"- {test_save_path['2nd.template']}\")\n","    testset_template_2ndstep.to_pickle(test_save_path['2nd.template'])"],"metadata":{"id":"hQsq2gOHiUKW","executionInfo":{"status":"ok","timestamp":1681208218339,"user_tz":-420,"elapsed":837,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# trainset, testset = train_test_split(struct_log, test_size=test_portion, random_state=seed, shuffle=False)\n","# trainset = trainset.reset_index()\n","# testset = testset.reset_index()"],"metadata":{"id":"pu2-O1s9wxgF","executionInfo":{"status":"ok","timestamp":1681207197189,"user_tz":-420,"elapsed":3,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(struct_log[[\"Content\", \"EventId\"]].groupby(\"Content\").first().reset_index())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"bE4qzBK1zIL9","executionInfo":{"status":"ok","timestamp":1681208188854,"user_tz":-420,"elapsed":2077,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}},"outputId":"08b351b9-6ab9-4d78-db8f-771f27b04867"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  Content   EventId\n","0                                               , max=366  7a55cdb4\n","1                                                       0  36ad086d\n","2       0 microseconds spent in the rbs signal handler...  09b67ed8\n","3                                             04, max=366  7a55cdb4\n","4             0:00000000 1:00003000 2:1eeeeeee 3:000c95f0  ed6b71a8\n","...                                                   ...       ...\n","358351         underflow exception......................0  53e11c49\n","358352         underflow exception......................1  53e11c49\n","358353                wait state enable.................0  10844260\n","358354         write buffer commit threshold............2  713c1974\n","358355                                              x=366  209d3cfa\n","\n","[358356 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-dd27ff7b-f1fe-4635-9be3-e80cc24a7569\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Content</th>\n","      <th>EventId</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>, max=366</td>\n","      <td>7a55cdb4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>36ad086d</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0 microseconds spent in the rbs signal handler...</td>\n","      <td>09b67ed8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>04, max=366</td>\n","      <td>7a55cdb4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0:00000000 1:00003000 2:1eeeeeee 3:000c95f0</td>\n","      <td>ed6b71a8</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>358351</th>\n","      <td>underflow exception......................0</td>\n","      <td>53e11c49</td>\n","    </tr>\n","    <tr>\n","      <th>358352</th>\n","      <td>underflow exception......................1</td>\n","      <td>53e11c49</td>\n","    </tr>\n","    <tr>\n","      <th>358353</th>\n","      <td>wait state enable.................0</td>\n","      <td>10844260</td>\n","    </tr>\n","    <tr>\n","      <th>358354</th>\n","      <td>write buffer commit threshold............2</td>\n","      <td>713c1974</td>\n","    </tr>\n","    <tr>\n","      <th>358355</th>\n","      <td>x=366</td>\n","      <td>209d3cfa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>358356 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd27ff7b-f1fe-4635-9be3-e80cc24a7569')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dd27ff7b-f1fe-4635-9be3-e80cc24a7569 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dd27ff7b-f1fe-4635-9be3-e80cc24a7569');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["kf = KFold(n_splits=cv, shuffle=False)\n","for i, (train_index, test_index) in enumerate(kf.split(struct_log)):\n","  print(f\"{i + 1}/{cv} fold:\")\n","  trainset = struct_log.iloc[train_index].reset_index(drop=True)\n","  testset =  struct_log.iloc[test_index].reset_index(drop=True)\n","\n","  pipeline(\n","      trainset, pkl_train_path[i], \n","      testset, pkl_test_path[i],\n","      []\n","      )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"czd48cScu7K5","executionInfo":{"status":"ok","timestamp":1681215904050,"user_tz":-420,"elapsed":7679223,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}},"outputId":"456d49d4-66f1-4a51-e200-b1ba0267dc82"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["1/3 fold:\n","TRAIN SECTION\n","Log Parsing 2nd Step\n","tokenize unique contents\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 307692/307692 [00:02<00:00, 141930.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["measure token sequence length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 307692/307692 [00:00<00:00, 819947.42it/s] \n"]},{"output_type":"stream","name":"stdout","text":["build new column: 'EventId_length'\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 307692/307692 [00:02<00:00, 107288.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["group tokens by id\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 378/378 [00:00<00:00, 576.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["calculate entropy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 378/378 [00:00<00:00, 414.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["threshold: 0.039558052120010345\n","tokenize unique contents\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 307692/307692 [00:02<00:00, 132504.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["measure token sequence length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 307692/307692 [00:00<00:00, 868178.75it/s] \n"]},{"output_type":"stream","name":"stdout","text":["build new column: 'EventId_length'\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 307692/307692 [00:02<00:00, 107832.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["group tokens by id\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 378/378 [00:00<00:00, 583.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["calculate unknow pattern entropy\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["transform X to Y\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142328/3142328 [00:49<00:00, 63354.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(Parameters) measure list length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142328/3142328 [00:03<00:00, 890830.67it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Entity Labeling\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142328/3142328 [01:29<00:00, 34969.04it/s] \n","100%|██████████| 3142328/3142328 [00:38<00:00, 81268.71it/s]\n","100%|██████████| 3142328/3142328 [00:16<00:00, 187275.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["('ParameterList') parse string to list\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142328/3142328 [00:11<00:00, 276622.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["('ParameterList') measure list length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142328/3142328 [00:03<00:00, 883816.25it/s] \n"]},{"output_type":"stream","name":"stdout","text":["prepare saving\n","saving:\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv0_train.log_ident_structured.pkl\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv0_train.log_ident_templates.pkl\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv0_train.2nd_log_ident_templates.pkl\n","TEST SECTION\n","Log Parsing 2nd Step\n","tokenize unique contents\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 108017/108017 [00:00<00:00, 325273.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["measure token sequence length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 108017/108017 [00:00<00:00, 773772.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["build new column: 'EventId_length'\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 108017/108017 [00:00<00:00, 108770.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["group tokens by id\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 193/193 [00:00<00:00, 1539.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["calculate unknow pattern entropy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6677/6677 [01:59<00:00, 55.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["transform X to Y\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571165/1571165 [00:19<00:00, 82263.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(Parameters) measure list length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571165/1571165 [00:01<00:00, 892933.35it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Entity Labeling\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571165/1571165 [00:22<00:00, 71241.35it/s]\n","100%|██████████| 1571165/1571165 [00:16<00:00, 93864.30it/s]\n","100%|██████████| 1571165/1571165 [00:03<00:00, 427904.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["('ParameterList') parse string to list\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571165/1571165 [00:08<00:00, 185928.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["('ParameterList') measure list length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571165/1571165 [00:01<00:00, 845279.08it/s] \n"]},{"output_type":"stream","name":"stdout","text":["prepare saving\n","saving:\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv0_test.log_ident_structured.pkl\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv0_test.log_ident_templates.pkl\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv0_test.2nd_log_ident_templates.pkl\n","2/3 fold:\n","TRAIN SECTION\n","Log Parsing 2nd Step\n","tokenize unique contents\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 290981/290981 [00:01<00:00, 193361.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["measure token sequence length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 290981/290981 [00:00<00:00, 831350.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["build new column: 'EventId_length'\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 290981/290981 [00:02<00:00, 99656.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["group tokens by id\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 362/362 [00:00<00:00, 497.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["calculate entropy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 362/362 [00:00<00:00, 414.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["threshold: 0.033924746926322726\n","tokenize unique contents\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 290981/290981 [00:01<00:00, 190773.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["measure token sequence length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 290981/290981 [00:00<00:00, 753167.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["build new column: 'EventId_length'\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 290981/290981 [00:02<00:00, 106052.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["group tokens by id\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 362/362 [00:00<00:00, 580.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["calculate unknow pattern entropy\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["transform X to Y\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142329/3142329 [00:41<00:00, 76078.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(Parameters) measure list length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142329/3142329 [00:03<00:00, 887736.81it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Entity Labeling\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142329/3142329 [01:20<00:00, 39099.61it/s] \n","100%|██████████| 3142329/3142329 [00:37<00:00, 84105.37it/s]\n","100%|██████████| 3142329/3142329 [00:15<00:00, 200821.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["('ParameterList') parse string to list\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142329/3142329 [00:10<00:00, 291632.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["('ParameterList') measure list length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142329/3142329 [00:03<00:00, 900097.64it/s] \n"]},{"output_type":"stream","name":"stdout","text":["prepare saving\n","saving:\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv1_train.log_ident_structured.pkl\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv1_train.log_ident_templates.pkl\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv1_train.2nd_log_ident_templates.pkl\n","TEST SECTION\n","Log Parsing 2nd Step\n","tokenize unique contents\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 128890/128890 [00:00<00:00, 265069.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["measure token sequence length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 128890/128890 [00:00<00:00, 224781.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["build new column: 'EventId_length'\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 128890/128890 [00:02<00:00, 49717.82it/s] \n"]},{"output_type":"stream","name":"stdout","text":["group tokens by id\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 227/227 [00:00<00:00, 1262.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["calculate unknow pattern entropy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 688/688 [00:00<00:00, 1013.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["transform X to Y\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571164/1571164 [00:20<00:00, 75309.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(Parameters) measure list length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571164/1571164 [00:01<00:00, 868511.48it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Entity Labeling\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571164/1571164 [00:31<00:00, 49909.01it/s]\n","100%|██████████| 1571164/1571164 [00:17<00:00, 88553.02it/s]\n","100%|██████████| 1571164/1571164 [00:04<00:00, 362151.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["('ParameterList') parse string to list\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571164/1571164 [00:08<00:00, 181283.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["('ParameterList') measure list length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571164/1571164 [00:01<00:00, 917597.52it/s] \n"]},{"output_type":"stream","name":"stdout","text":["prepare saving\n","saving:\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv1_test.log_ident_structured.pkl\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv1_test.log_ident_templates.pkl\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv1_test.2nd_log_ident_templates.pkl\n","3/3 fold:\n","TRAIN SECTION\n","Log Parsing 2nd Step\n","tokenize unique contents\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 180101/180101 [00:00<00:00, 288132.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["measure token sequence length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 180101/180101 [00:00<00:00, 812980.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["build new column: 'EventId_length'\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 180101/180101 [00:01<00:00, 107300.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["group tokens by id\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 268/268 [00:00<00:00, 391.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["calculate entropy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 268/268 [00:01<00:00, 185.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["threshold: 0.07807015597200395\n","tokenize unique contents\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 180101/180101 [00:01<00:00, 112418.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["measure token sequence length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 180101/180101 [00:00<00:00, 442092.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["build new column: 'EventId_length'\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 180101/180101 [00:01<00:00, 93034.49it/s] \n"]},{"output_type":"stream","name":"stdout","text":["group tokens by id\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 268/268 [00:00<00:00, 1019.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["calculate unknow pattern entropy\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["transform X to Y\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142329/3142329 [00:33<00:00, 93461.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(Parameters) measure list length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142329/3142329 [00:03<00:00, 904100.13it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Entity Labeling\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142329/3142329 [00:54<00:00, 57236.16it/s]\n","100%|██████████| 3142329/3142329 [00:34<00:00, 91610.15it/s]\n","100%|██████████| 3142329/3142329 [00:09<00:00, 321850.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["('ParameterList') parse string to list\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142329/3142329 [00:11<00:00, 267821.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["('ParameterList') measure list length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3142329/3142329 [00:03<00:00, 926949.02it/s] \n"]},{"output_type":"stream","name":"stdout","text":["prepare saving\n","saving:\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv2_train.log_ident_structured.pkl\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv2_train.log_ident_templates.pkl\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv2_train.2nd_log_ident_templates.pkl\n","TEST SECTION\n","Log Parsing 2nd Step\n","tokenize unique contents\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 185339/185339 [00:01<00:00, 166746.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["measure token sequence length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 185339/185339 [00:00<00:00, 745550.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["build new column: 'EventId_length'\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 185339/185339 [00:01<00:00, 104586.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["group tokens by id\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 327/327 [00:00<00:00, 610.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["calculate unknow pattern entropy\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 71233/71233 [1:49:18<00:00, 10.86it/s] \n"]},{"output_type":"stream","name":"stdout","text":["transform X to Y\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571164/1571164 [00:32<00:00, 49023.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(Parameters) measure list length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571164/1571164 [00:01<00:00, 846961.56it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Entity Labeling\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571164/1571164 [00:45<00:00, 34431.82it/s] \n","100%|██████████| 1571164/1571164 [00:20<00:00, 77072.44it/s]\n","100%|██████████| 1571164/1571164 [00:05<00:00, 284922.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["('ParameterList') parse string to list\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571164/1571164 [00:09<00:00, 173899.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["('ParameterList') measure list length\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1571164/1571164 [00:01<00:00, 905206.74it/s] \n"]},{"output_type":"stream","name":"stdout","text":["prepare saving\n","saving:\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv2_test.log_ident_structured.pkl\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv2_test.log_ident_templates.pkl\n","- /content/drive/MyDrive/Colab Notebooks/Parsed_Log/BGL.2ndstep-log-parsing.cv2_test.2nd_log_ident_templates.pkl\n"]}]},{"cell_type":"code","source":["for i, (train_index, test_index) in enumerate(kf.split(struct_log)):\n","  print(f\"{i + 1}/{cv} fold:\")\n","  print(f\"{len(train_index)} ({len(train_index) / len(struct_log)})\")\n","  print(f\"{len(test_index)} ({len(test_index) / len(struct_log)})\")"],"metadata":{"id":"d-quEFv9osN1","executionInfo":{"status":"ok","timestamp":1681215911147,"user_tz":-420,"elapsed":509,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"02dda5e8-b793-461a-8868-ef3d5416c923"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["1/3 fold:\n","3142328 (0.6666665252287423)\n","1571165 (0.33333347477125774)\n","2/3 fold:\n","3142329 (0.6666667373856289)\n","1571164 (0.33333326261437113)\n","3/3 fold:\n","3142329 (0.6666667373856289)\n","1571164 (0.33333326261437113)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hwu5nd98ylT8"},"execution_count":null,"outputs":[]}]}