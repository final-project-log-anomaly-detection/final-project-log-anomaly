{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assert_is_fit(func):\n",
    "    def inner(self, *args, **kwargs):\n",
    "        assert self._LogParser__is_fit, \"model has not fit.\"\n",
    "        return self.func(*args, **kwargs)\n",
    "    return inner\n",
    "\n",
    "class LogParser(object):\n",
    "    \n",
    "    def __init__(self, output_dir=\"./output\") -> None:\n",
    "        self.output_dir = output_dir\n",
    "        self.__is_fit = False\n",
    "     \n",
    "    def generate_logformat_regex(self, logformat):\n",
    "        \"\"\" Function to generate regular expression to split log messages\n",
    "        \"\"\"\n",
    "        headers = []\n",
    "        splitters = re.split(r'(<[^<>]+>)', logformat)\n",
    "        regex = ''\n",
    "\n",
    "        for k in range(len(splitters)):\n",
    "            if k % 2 == 0:\n",
    "                splitter = re.sub(' +', '\\\\\\s+', splitters[k])\n",
    "                regex += splitter\n",
    "            else:\n",
    "                header = splitters[k].strip('<').strip('>')\n",
    "                regex += '(?P<%s>.*?)' % header  # such as (?P<Date>.*?)\n",
    "                headers.append(header)\n",
    "\n",
    "        regex = re.compile('^' + regex + '$')\n",
    "        return headers, regex\n",
    "    \n",
    "    @_assert_is_fit\n",
    "    def log_to_dataframe(self, log_file):\n",
    "        \"\"\" Function to transform log file to dataframe \n",
    "        \"\"\"\n",
    "        log_messages = []\n",
    "        with open(log_file, 'r') as fin:\n",
    "            for line in tqdm(fin.readlines(), desc=\"log file reading :\"):\n",
    "                try:\n",
    "                    match = self.regex_log_format.search(line.strip())\n",
    "                    message = match.groupdict()\n",
    "                    log_messages.append(message)\n",
    "                except Exception as e:\n",
    "                    print(f\"\\u001b[31mERROR-LINE: {line}\")\n",
    "            fin.close()\n",
    "        \n",
    "        logdf = pd.concat([\n",
    "            pd.Series(range(1, len(log_messages) + 1), name=\"LineId\"), \n",
    "            pd.DataFrame(log_messages)\n",
    "            ], axis=1)\n",
    "        \n",
    "        return logdf\n",
    "    \n",
    "    @_assert_is_fit\n",
    "    def parse(self, log_file):\n",
    "        log_df = self.log_to_dataframe(log_file)\n",
    "        return log_df\n",
    "    \n",
    "    def fit(self, log_format):\n",
    "        self.log_format = log_format\n",
    "        self.headers, self.regex_log_format = self.generate_logformat_regex(log_format)\n",
    "        self.__is_fit = True\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0 (default, Nov  6 2019, 15:49:01) \n[Clang 4.0.1 (tags/RELEASE_401/final)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb13736d41bd87c4a6da44de2a53cc3b2c3a6ec16bd51d52b3766a818a83a02f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
