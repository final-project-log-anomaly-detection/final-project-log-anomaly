{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"go84TQFemVtB","executionInfo":{"status":"ok","timestamp":1674629630120,"user_tz":-420,"elapsed":122502,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}},"outputId":"8af4f252-9221-4565-a985-5cbad7a9a44e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"hMz2pNZemTtO","executionInfo":{"status":"ok","timestamp":1674629635493,"user_tz":-420,"elapsed":3289,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from gensim.models import Word2Vec, KeyedVectors\n","from nltk.tokenize import RegexpTokenizer\n","\n","import os\n","import pickle\n","from tqdm import tqdm\n","\n","seed = 42\n","np.random.seed(seed)"]},{"cell_type":"markdown","metadata":{"id":"nU_LZA0wmTtS"},"source":["Preprocess Data (Splited by time-series)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"4lBQEgwimTtU","executionInfo":{"status":"ok","timestamp":1674629666889,"user_tz":-420,"elapsed":29460,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"outputs":[],"source":["import re\n","\n","#######\n","def text_cleansing(text):\n","    regex_except_token = r'\\B(?!<\\w+>\\B)[^\\w\\s]'\n","    regex_expect_words = r'[^\\w<>]+'\n","    output = re.sub(regex_except_token, '', text)\n","    output = re.sub(regex_expect_words, ' ', output)\n","    return output\n","\n","csv_dir = \"/content/drive/MyDrive/Colab Notebooks/Drain_result/\"\n","\n","struct_log = pd.read_csv( csv_dir + \"BGL.log_structured.csv\")\n","template_log = pd.read_csv( csv_dir + \"BGL.log_templates.csv\")\n","\n","struct_log[\"Label\"] = struct_log[\"Label\"].apply(lambda x: int(x != \"-\"))\n","struct_log.sort_values(\"Time\", inplace=True)\n","struct_log[struct_log[\"Label\"] == 1].Date.value_counts().sort_index()\n","split_date = struct_log[struct_log.Label == 1].Date.values[0]\n","\n","trainset = struct_log[struct_log.Date < split_date]\n","testset = struct_log[struct_log.Date >= split_date] \n","eventid_train = trainset.EventId.unique() \n","eventid_test = testset.EventId.unique() "]},{"cell_type":"code","source":["template_log_train = template_log[template_log[\"EventId\"].isin(eventid_train)]\n","template_log_test = template_log[template_log[\"EventId\"].isin(eventid_test)]"],"metadata":{"id":"GwcOSEsZniXP","executionInfo":{"status":"ok","timestamp":1674629669940,"user_tz":-420,"elapsed":708,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["template_log_train[\"EventTemplate_cleansed\"] = template_log_train.EventTemplate.map(text_cleansing)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnX6OWmnnRLP","executionInfo":{"status":"ok","timestamp":1674629673466,"user_tz":-420,"elapsed":910,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}},"outputId":"3380a066-f80d-41e7-acad-f0b2dad05858"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-8d62d18c9600>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  template_log_train[\"EventTemplate_cleansed\"] = template_log_train.EventTemplate.map(text_cleansing)\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"jgPmsx2ZmTtW","outputId":"1bb40440-477a-446f-cba6-8d23cc6d4c8c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674629676731,"user_tz":-420,"elapsed":475,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-d2b0c4ccd385>:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  template_log_train[\"EventTemplate_token\"] = pd.Series(token_train_list)\n","Mapping ID & token: 100%|██████████| 15/15 [00:00<00:00, 80763.23it/s]\n","<ipython-input-6-d2b0c4ccd385>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  trainset[\"Token\"] = trainset.EventId.map(lambda id: map_token_train[id])\n"]}],"source":["template_log_train_list = template_log_train[\"EventTemplate_cleansed\"].astype('str').tolist()\n","tokenizer = RegexpTokenizer(r'[A-Z][a-z]+|\\w+')\n","token_train_list = [ tokenizer.tokenize(sen) for sen in template_log_train_list ]\n","\n","template_log_train[\"EventTemplate_token\"] = pd.Series(token_train_list)\n","map_token_train = { row[0]: row[1] \\\n","    for row in tqdm(\n","        template_log_train[[\"EventId\", \"EventTemplate_token\"]].values,\n","        desc=\"Mapping ID & token\"\n","        ) }\n","trainset[\"Token\"] = trainset.EventId.map(lambda id: map_token_train[id])"]},{"cell_type":"code","source":["output_dir = \"/content/drive/MyDrive/Colab Notebooks/BGL_preprocessed_type2/\"\n","\n","if not os.path.exists(output_dir + \"/processed_<*>/\"):\n","  os.mkdir(output_dir + \"/processed_<*>\")\n","\n","output_dir = output_dir + \"/processed_<*>\""],"metadata":{"id":"z8rYfGuzobcv","executionInfo":{"status":"ok","timestamp":1674629680375,"user_tz":-420,"elapsed":904,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"MUWJTep0mTtX","executionInfo":{"status":"ok","timestamp":1674629684715,"user_tz":-420,"elapsed":1206,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"outputs":[],"source":["template_log_train.to_pickle(output_dir + \"/log_template.trainset.pkl\")\n","trainset.to_pickle(output_dir + \"/log_structured.trainset.pkl\")"]},{"cell_type":"code","source":["template_log_test[\"EventTemplate_cleansed\"] = template_log_test.EventTemplate.map(text_cleansing)\n","template_log_test_list = template_log_test[\"EventTemplate_cleansed\"].astype('str').tolist()\n","\n","token_test_list = [ tokenizer.tokenize(sen) for sen in template_log_test_list ]\n","\n","template_log_test[\"EventTemplate_token\"] = pd.Series(token_test_list)\n","map_token_test = { row[0]: row[1] \\\n","    for row in tqdm(\n","        template_log_test[[\"EventId\", \"EventTemplate_token\"]].values,\n","        desc=\"Mapping ID & token\"\n","        ) }\n","testset[\"Token\"] = testset.EventId.map(lambda id: map_token_test[id])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdJRyRSvqDbk","executionInfo":{"status":"ok","timestamp":1674629688071,"user_tz":-420,"elapsed":903,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}},"outputId":"a32a2d0c-f603-4e02-9dd6-6a24466731f9"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Mapping ID & token: 100%|██████████| 1126/1126 [00:00<00:00, 620113.75it/s]\n","<ipython-input-9-6727d8898076>:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  testset[\"Token\"] = testset.EventId.map(lambda id: map_token_test[id])\n"]}]},{"cell_type":"code","source":["testset.to_pickle(output_dir + \"/log_structured.testset.pkl\")\n","template_log_test.to_pickle(output_dir + \"/log_template.testset.pkl\")"],"metadata":{"id":"HZrcblX9p6YM","executionInfo":{"status":"ok","timestamp":1674629699698,"user_tz":-420,"elapsed":9284,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ImYR5TTcmTtX"},"source":["Preprocess Data (Splited by portion)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yPNXNwJ4mTtY"},"outputs":[],"source":["# from sklearn.model_selection import train_test_split\n","\n","# struct_log = pd.read_csv(\"./output/BGL/BGL.log_structured.csv\")\n","# template_log = pd.read_csv(\"./output/BGL/BGL.log_templates.csv\")\n","\n","# test_ratio = 0.4\n","# struct_log[\"Label\"] = struct_log[\"Label\"].apply(lambda x: int(x != \"-\"))\n","# struct_log.sort_values(\"Time\", inplace=True)\n","# struct_log[struct_log[\"Label\"] == 1].Date.value_counts().sort_index()\n","\n","# trainset, testset = train_test_split(struct_log, test_size=0.4, random_state=seed, shuffle=False)\n","# trainset = trainset[trainset[\"Label\"] == 0]\n","# eventid_train = trainset.EventId.unique()\n","# eventid_test = testset.EventId.unique()\n","\n","# template_log_train = template_log[template_log[\"EventId\"].isin(eventid_train)]\n","# template_log_test = template_log[template_log[\"EventId\"].isin(eventid_test)]\n","# template_log_train[\"EventTemplateIdent_cleansed\"] = template_log_train.EventTemplateIdent.map(text_cleansing)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_BnBeYRmTtZ"},"outputs":[],"source":["# template_log_train_list = template_log_train[\"EventTemplateIdent_cleansed\"].astype('str').tolist()\n","\n","# tokenizer = RegexpTokenizer(r'[A-Z][a-z]+|\\w+')\n","# token_train_list = [ tokenizer.tokenize(sen) for sen in template_log_train_list ]\n","\n","# template_log_train[\"EventTemplateIdent_token\"] = pd.Series(token_train_list)\n","# map_token_train = { row[0]: row[1] \\\n","#     for row in tqdm(\n","#         template_log_train[[\"EventId\", \"EventTemplateIdent_token\"]].values,\n","#         desc=\"Mapping ID & token\"\n","#         ) }\n","# trainset[\"Token\"] = trainset.EventId.map(lambda id: map_token_train[id])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1h5KHn3qmTtZ"},"outputs":[],"source":["# template_log_train.to_pickle(\"./output/BGL/processed/log_template.trainset.pkl\")\n","# trainset.to_pickle(\"./output/BGL/processed/log_structured.trainset.pkl\")\n","# testset.to_pickle(\"./output/BGL/processed/log_structured.testset.pkl\")\n","# template_log_test.to_pickle(\"./output/BGL/processed/log_structured.testset.pkl\")"]},{"cell_type":"code","source":["import gensim.downloader as api\n","\n","info = api.info()\n","for model_name, model_data in sorted(info['models'].items()):\n","    print(\n","        '%s (%d records): %s' % (\n","            model_name,\n","            model_data.get('num_records', -1),\n","            model_data['description'][:40] + '...',\n","        )\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L9SluRQjskZJ","executionInfo":{"status":"ok","timestamp":1674621038788,"user_tz":-420,"elapsed":17,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}},"outputId":"9d1e3640-199c-43c0-8e11-9379da5948b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["__testing_word2vec-matrix-synopsis (-1 records): [THIS IS ONLY FOR TESTING] Word vecrors ...\n","conceptnet-numberbatch-17-06-300 (1917247 records): ConceptNet Numberbatch consists of state...\n","fasttext-wiki-news-subwords-300 (999999 records): 1 million word vectors trained on Wikipe...\n","glove-twitter-100 (1193514 records): Pre-trained vectors based on  2B tweets,...\n","glove-twitter-200 (1193514 records): Pre-trained vectors based on 2B tweets, ...\n","glove-twitter-25 (1193514 records): Pre-trained vectors based on 2B tweets, ...\n","glove-twitter-50 (1193514 records): Pre-trained vectors based on 2B tweets, ...\n","glove-wiki-gigaword-100 (400000 records): Pre-trained vectors based on Wikipedia 2...\n","glove-wiki-gigaword-200 (400000 records): Pre-trained vectors based on Wikipedia 2...\n","glove-wiki-gigaword-300 (400000 records): Pre-trained vectors based on Wikipedia 2...\n","glove-wiki-gigaword-50 (400000 records): Pre-trained vectors based on Wikipedia 2...\n","word2vec-google-news-300 (3000000 records): Pre-trained vectors trained on a part of...\n","word2vec-ruscorpora-300 (184973 records): Word2vec Continuous Skipgram vectors tra...\n"]}]},{"cell_type":"code","source":["# Download \"GoogleNews-vectors-negative300.bin\" from:\n","# https://www.kaggle.com/datasets/leadbest/googlenewsvectorsnegative300\n","# or load model from API\n","model_path = api.load(\"word2vec-google-news-300\", return_path=True)\n","if os.path.exists(model_path):\n","  os.system(\"gzip -d {}\".format(model_path))\n","model_file = os.path.dirname(model_path) + \"/word2vec-google-news-300\""],"metadata":{"id":"FBTAo9kMtJaz","executionInfo":{"status":"ok","timestamp":1674621523233,"user_tz":-420,"elapsed":484460,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a42c75a0-960e-4450-a4e4-aedb6db41375"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ssZGlGOmTta"},"outputs":[],"source":["model = KeyedVectors.load_word2vec_format(model_file, binary = True)\n","\n","embedder = Word2Vec(size=300, min_count=1)\n","# embedder = Word2Vec(vector_size=300, min_count=1)\n","\n","embedder.build_vocab(token_train_list)\n","total_examples = embedder.corpus_count\n","\n","embedder.build_vocab([list(model.vocab.keys())], update=True)\n","# embedder.build_vocab([list(model.key_to_index.keys())], update=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nwhzKcCtmTtb"},"outputs":[],"source":["# embedder.wv.vectors_lockf = np.ones(len(embedder.wv), dtype=np.float32)\n","embedder.intersect_word2vec_format(model_file, binary=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k3702NTJmTtb","outputId":"6d8f17a8-b613-4308-cbb2-e658e5ab37ce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674622250034,"user_tz":-420,"elapsed":19,"user":{"displayName":"No Noseason","userId":"05219773639042295484"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"]},{"output_type":"execute_result","data":{"text/plain":["(1149, 1230)"]},"metadata":{},"execution_count":16}],"source":["embedder.train(token_train_list, total_examples=total_examples, epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pE7t-7sPmTtb"},"outputs":[],"source":["fine_tune_files = \"/content/drive/MyDrive/Colab Notebooks/word2Vec/BGL-word2vec-fine-tune-embedder-no-parameter-labeling.txt\"\n","embedder.wv.save_word2vec_format(fine_tune_files, binary=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p9kh5_ENmTtc"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"torch-gpu","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15 (default, Nov 24 2022, 08:57:44) \n[Clang 14.0.6 ]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ce4081ce2b9ab9ecfe855a4e9c840ae25394b5d73782b2027cad0c1ddfa0aa02"}},"colab":{"provenance":[],"machine_shape":"hm"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}